# è¯­è¨€æ¨¡å‹

## ğŸ¼ æ¨¡å‹åˆ—è¡¨

+ `GPT2`ï¼š[ã€ŠLanguage Models are Unsupervised Multitask Learnersã€‹](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)

+ `ChatGLM-6b`ï¼š[ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹](https://github.com/THUDM/ChatGLM-6B)

+ `LLaMA`ï¼š[LLaMA: Open and Efficient Foundation Language Models](https://github.com/facebookresearch/llama)

## PYTORCHé•œåƒ

æ„å»ºé•œåƒ

```docker
bash docker/build.sh 
```

å¯åŠ¨å®¹å™¨

```docker
bash docker/run.sh
```

è¿›å…¥å®¹å™¨

```docker
docker exec -it llm /bin/bash
```

## ğŸ“š æ•°æ®é›†

1. 50 ä¸‡æ¡ä¸­æ–‡ `ChatGPT` æŒ‡ä»¤ `Belle` æ•°æ®é›†ï¼š[BelleGroup/train_0.5M_CN](https://huggingface.co/datasets/BelleGroup/train_0.5M_CN)
2. 100 ä¸‡æ¡ä¸­æ–‡ `ChatGPT` æŒ‡ä»¤ `Belle` æ•°æ®é›†ï¼š[BelleGroup/train_1M_CN](https://huggingface.co/datasets/BelleGroup/train_1M_CN)
3. 5 ä¸‡æ¡è‹±æ–‡ `ChatGPT` æŒ‡ä»¤ `Alpaca` æ•°æ®é›†ï¼š[50k English Stanford Alpaca dataset](https://github.com/tatsu-lab/stanford_alpaca#data-release)
4. 2 ä¸‡æ¡ä¸­æ–‡ `ChatGPT` æŒ‡ä»¤ `Alpaca` æ•°æ®é›†ï¼š[shibing624/alpaca-zh](https://huggingface.co/datasets/shibing624/alpaca-zh)
5. 69 ä¸‡æ¡ä¸­æ–‡æŒ‡ä»¤ `Guanaco` æ•°æ®é›†(`Belle` 50 ä¸‡æ¡ + `Guanaco` 19 ä¸‡æ¡)ï¼š[Chinese-Vicuna/guanaco_belle_merge_v1.0](https://huggingface.co/datasets/Chinese-Vicuna/guanaco_belle_merge_v1.0)



## [æ¨¡å‹è®­ç»ƒ](./llmtuning)

é’ˆå¯¹æ¨¡å‹è¿›è¡Œçº¯æ–‡æœ¬é¢„è®­ç»ƒã€æŒ‡ä»¤å¾®è°ƒå’Œå‚æ•°é«˜æ•ˆå¾®è°ƒç­‰

## [æ¨¡å‹æ•ˆæœ](./service)

æ¨¡å‹ç”Ÿæˆæ•ˆæœå±•ç¤º

## [æ¨¡å‹è¯„ä¼°](./evaluate)

ç»™å®šä»»åŠ¡æˆ–æŒ‡ä»¤ï¼Œè¯„ä¼°ä¸åŒæ¨¡å‹çš„ç”Ÿæˆæ•ˆæœ