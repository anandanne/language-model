import os
import shutil

import gradio as gr

import kg_chatglm as kb


def get_file_list():
    if not os.path.exists("content"):
        return []
    return [f for f in os.listdir("content")]


file_list = get_file_list()
embedding_model_dict_list = list(kb.embedding_model_dict)
llm_model_dict_list = ["chatglm-6b"]


def upload_file(file):
    if not os.path.exists("content"):
        os.mkdir("content")

    filename = os.path.basename(file.name)
    shutil.move(file.name, "content/" + filename)
    # file_listÈ¶ñ‰ΩçÊèíÂÖ•Êñ∞‰∏ä‰º†ÁöÑÊñá‰ª∂
    file_list.insert(0, filename)

    return gr.Dropdown.update(choices=file_list, value=filename)


def get_answer(query, vector_store, history):
    resp, history = kb.get_knowledge_based_answer(
        query=query, vector_store=vector_store, chat_history=history)
    return history, history


def get_model_status(history):
    return history + [[None, "Ê®°ÂûãÂ∑≤ÂÆåÊàêÂä†ËΩΩÔºåËØ∑ÈÄâÊã©Ë¶ÅÂä†ËΩΩÁöÑÊñáÊ°£"]]


def get_file_status(history):
    return history + [[None, "ÊñáÊ°£Â∑≤ÂÆåÊàêÂä†ËΩΩÔºåËØ∑ÂºÄÂßãÊèêÈóÆ"]]


with gr.Blocks(css="""
.importantButton {
    background: linear-gradient(45deg, #7e0570,#5d1c99, #6e00ff) !important;
    border: none !important;
}

.importantButton:hover {
    background: linear-gradient(45deg, #ff00e0,#8500ff, #6e00ff) !important;
    border: none !important;
}

""") as demo:
    gr.Markdown(
        f"""
# üéâlangchain-ChatGLM WebUIüéâ

üëç [https://github.com/imClumsyPanda/langchain-ChatGLM](https://github.com/imClumsyPanda/langchain-ChatGLM)

""")
    with gr.Row():
        with gr.Column(scale=2):
            chatbot = gr.Chatbot([[None, """Ê¨¢Ëøé‰ΩøÁî® langchain-ChatGLM Web UIÔºåÂºÄÂßãÊèêÈóÆÂâçÔºåËØ∑‰æùÊ¨°Â¶Ç‰∏ã 3 ‰∏™Ê≠•È™§Ôºö
1. ÈÄâÊã©ËØ≠Ë®ÄÊ®°Âûã„ÄÅEmbedding Ê®°ÂûãÂèäÁõ∏ÂÖ≥ÂèÇÊï∞ÂêéÁÇπÂáª"step.1: setting"ÔºåÂπ∂Á≠âÂæÖÂä†ËΩΩÂÆåÊàêÊèêÁ§∫
2. ‰∏ä‰º†ÊàñÈÄâÊã©Â∑≤ÊúâÊñá‰ª∂‰Ωú‰∏∫Êú¨Âú∞Áü•ËØÜÊñáÊ°£ËæìÂÖ•ÂêéÁÇπÂáª"step.2 loading"ÔºåÂπ∂Á≠âÂæÖÂä†ËΩΩÂÆåÊàêÊèêÁ§∫
3. ËæìÂÖ•Ë¶ÅÊèê‰∫§ÁöÑÈóÆÈ¢òÂêéÁÇπÂáª"step.3 asking" """]],
                                 elem_id="chat-box",
                                 show_label=False).style(height=600)
        with gr.Column(scale=1):
            with gr.Column():
                llm_model = gr.Radio(
                    llm_model_dict_list,
                    label="llm model",
                    value="chatglm-6b",
                    interactive=True
                )
                LLM_HISTORY_LEN = gr.Slider(
                    1,
                    10,
                    value=3,
                    step=1,
                    label="LLM history len",
                    interactive=True
                )
                embedding_model = gr.Radio(
                    embedding_model_dict_list,
                    label="embedding model",
                    value="text2vec",
                    interactive=True
                )
                VECTOR_SEARCH_TOP_K = gr.Slider(
                    1,
                    20,
                    value=6,
                    step=1,
                    label="vector search top k",
                    interactive=True
                )
                load_model_button = gr.Button("step.1Ôºösetting")
                load_model_button.click(
                    lambda *args:
                    kb.init_cfg(args[0], args[1], args[2], args[3]),
                    show_progress=True,
                    api_name="init_cfg",
                    inputs=[llm_model, embedding_model, VECTOR_SEARCH_TOP_K, LLM_HISTORY_LEN]
                ).then(
                    get_model_status, chatbot, chatbot
                )

            with gr.Column():
                with gr.Tab("select"):
                    selectFile = gr.Dropdown(
                        file_list,
                        label="content file",
                        interactive=True,
                        value=file_list[0] if len(file_list) > 0 else None
                    )
                with gr.Tab("upload"):
                    file = gr.File(
                        label="content file",
                        file_types=['.txt', '.md', '.docx']
                    ).style(height=100)
                    # Â∞Ü‰∏ä‰º†ÁöÑÊñá‰ª∂‰øùÂ≠òÂà∞contentÊñá‰ª∂Â§π‰∏ã,Âπ∂Êõ¥Êñ∞‰∏ãÊãâÊ°Ü
                    file.upload(
                        upload_file,
                        inputs=file,
                        outputs=selectFile
                    )

                history = gr.State([])
                vector_store = gr.State()
                load_button = gr.Button("step.2Ôºöloading")
                load_button.click(
                    lambda fileName:
                    kb.init_knowledge_vector_store(
                        "content/" + fileName),
                    show_progress=True,
                    api_name="init_knowledge_vector_store",
                    inputs=selectFile,
                    outputs=vector_store
                ).then(
                    get_file_status,
                    chatbot,
                    chatbot,
                    show_progress=True,
                )

    with gr.Row():
        with gr.Column(scale=2):
            query = gr.Textbox(
                show_label=False,
                placeholder="Prompts",
                lines=1,
                value="Áî®200Â≠óÊÄªÁªì‰∏Ä‰∏ã"
            ).style(container=False)
        with gr.Column(scale=1):
            generate_button = gr.Button("step.3Ôºöasking", elem_classes="importantButton")
            generate_button.click(
                get_answer,
                [query, vector_store, chatbot],
                [chatbot, history],
                api_name="get_knowledge_based_answer"
            )

demo.queue(concurrency_count=3).launch(
    server_name='0.0.0.0', inbrowser=False)
